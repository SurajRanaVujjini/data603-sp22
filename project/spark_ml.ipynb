{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a2b25170-a810-4cc8-ad54-eab23bdccf47",
   "metadata": {},
   "source": [
    "## Importing necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6d9fa080-32ec-4b3f-a86d-52461e6efebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType, DateType, DoubleType\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.ml.feature import VectorAssembler, OneHotEncoder, StringIndexer\n",
    "from pyspark.ml.classification import DecisionTreeClassifier\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator, MulticlassClassificationEvaluator\n",
    "from pyspark.sql.functions import col,isnan, when, count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9b06ae8c-e745-489a-b5c3-c25a9a3ed438",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f9c9e5f-cc59-4f31-90d1-f5a50c4e499b",
   "metadata": {},
   "source": [
    "## Reading the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7f2a9473-42fa-40a0-a4ee-f330583e5835",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.options(header = \"true\", inferSchema = \"true\", nullValue = \"NA\").csv(\"bookings.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0dca5b09-f4e5-4913-a148-07996d52920e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Booking_ID: string (nullable = true)\n",
      " |-- no_of_adults: integer (nullable = true)\n",
      " |-- no_of_children: integer (nullable = true)\n",
      " |-- no_of_weekend_nights: integer (nullable = true)\n",
      " |-- no_of_week_nights: integer (nullable = true)\n",
      " |-- type_of_meal_plan: string (nullable = true)\n",
      " |-- required_car_parking_space: integer (nullable = true)\n",
      " |-- room_type_reserved: string (nullable = true)\n",
      " |-- lead_time: integer (nullable = true)\n",
      " |-- arrival_year: integer (nullable = true)\n",
      " |-- arrival_month: integer (nullable = true)\n",
      " |-- arrival_date: integer (nullable = true)\n",
      " |-- market_segment_type: string (nullable = true)\n",
      " |-- repeated_guest: integer (nullable = true)\n",
      " |-- no_of_previous_cancellations: integer (nullable = true)\n",
      " |-- no_of_previous_bookings_not_canceled: integer (nullable = true)\n",
      " |-- avg_price_per_room: double (nullable = true)\n",
      " |-- no_of_special_requests: integer (nullable = true)\n",
      " |-- booking_status: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a33c7552-3827-40f9-b1fd-ece6f8f23275",
   "metadata": {},
   "source": [
    "## Dropping columns that are not required"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d36e2e5a-c7df-4c1f-a6b8-1e9468330ffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop('Booking_ID','arrival_year')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d498a370-ae64-4644-828a-93cec3d55a80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+--------------+--------------------+-----------------+-----------------+--------------------------+------------------+---------+-------------+------------+-------------------+--------------+----------------------------+------------------------------------+------------------+----------------------+--------------+\n",
      "|no_of_adults|no_of_children|no_of_weekend_nights|no_of_week_nights|type_of_meal_plan|required_car_parking_space|room_type_reserved|lead_time|arrival_month|arrival_date|market_segment_type|repeated_guest|no_of_previous_cancellations|no_of_previous_bookings_not_canceled|avg_price_per_room|no_of_special_requests|booking_status|\n",
      "+------------+--------------+--------------------+-----------------+-----------------+--------------------------+------------------+---------+-------------+------------+-------------------+--------------+----------------------------+------------------------------------+------------------+----------------------+--------------+\n",
      "|           0|             0|                   0|                0|                0|                         0|                 0|        0|            0|           0|                  0|             0|                           0|                                   0|                 0|                     0|             0|\n",
      "+------------+--------------+--------------------+-----------------+-----------------+--------------------------+------------------+---------+-------------+------------+-------------------+--------------+----------------------------+------------------------------------+------------------+----------------------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col,isnan, when, count\n",
    "df.select([count(when(isnan(c) | col(c).isNull(), c)).alias(c) for c in df.columns]\n",
    "   ).show()\n",
    "#There are no null values in this dataset to drop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a3a07f06-a0f5-42f0-8088-742dc57067d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sperating columns into numerical and categorical columns for \n",
    "num_cols = [colname for colname, dtype in df.dtypes if dtype in ('int', 'double')]\n",
    "categorical_cols = [colname for colname, dtype in df.dtypes if dtype == 'string']\n",
    "target_col = ['booking_status']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c2cad1e-1560-433b-a259-65054d906b81",
   "metadata": {},
   "source": [
    "## Splitting the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a180e8e7-9977-4dfa-a797-145e38978d6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, test_df = df.randomSplit([0.8, 0.2], seed=12345)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f48dc46-cd5f-4ac7-9a51-72ec4ef7329a",
   "metadata": {},
   "source": [
    "## Preprocessing the categorical columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "16e80b50-7125-4732-9a34-815d9633e5c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "indexOutput = [x + '_idx' for x in categorical_cols]\n",
    "stringIndexer = StringIndexer(inputCols=categorical_cols, outputCols=indexOutput)\n",
    "\n",
    "oheOutput = [x + '_ohe' for x in categorical_cols]\n",
    "ohe = OneHotEncoder(inputCols=indexOutput, outputCols=oheOutput)\n",
    "\n",
    "targetIndexer = StringIndexer(inputCol='booking_status', outputCol='label')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8f254f8-93c3-4279-9305-9766b385f805",
   "metadata": {},
   "source": [
    "## Building ML model - Decision tree classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "43b798b7-986a-47f1-85d2-8c746d09d3d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#vector assembler\n",
    "assemblerInput = oheOutput + num_cols\n",
    "vecAssembler = VectorAssembler(inputCols=assemblerInput, outputCol='features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "03e3a4ff-4737-4754-9495-61a88386f813",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtc = DecisionTreeClassifier(featuresCol='features', labelCol='label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5e3ef5dc-8332-459a-8d24-70847e5081db",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating pipeline\n",
    "pipeline = Pipeline(stages=[stringIndexer, ohe, targetIndexer, vecAssembler, dtc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a8d46e58-611c-4b20-9484-c445809320d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "binaryEval = BinaryClassificationEvaluator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "aa5fe506-ad38-49e3-b070-dab8d25e6e83",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Assigning parameter for hypterparameter tuning\n",
    "paramGrid = (ParamGridBuilder()\n",
    "             .addGrid(dtc.impurity, ['gini', 'entropy'])\n",
    "             .addGrid(dtc.maxBins, [5, 10, 15])\n",
    "             .addGrid(dtc.minInfoGain, [0.0, 0.2, 0.4])\n",
    "             .addGrid(dtc.maxDepth, [3, 5, 7])\n",
    "             .build()\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "edff2f8e-10fb-4a7e-9542-617813be00c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cross validate with 3 folds\n",
    "cv = CrossValidator(estimator=pipeline, \n",
    "                    estimatorParamMaps=paramGrid, \n",
    "                    evaluator=binaryEval, \n",
    "                    numFolds=4, \n",
    "                    parallelism=4)\n",
    "# fit the model\n",
    "cvModel = cv.fit(train_df)\n",
    "# get best model \n",
    "bestModel = cvModel.bestModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ca49b56c-54ce-45a6-bd0f-23fdafd0e6cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PipelineModel_77be8c6863c7"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bestModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3bc23f94-ce2c-42c3-9327-59e4378c4be1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters:\n",
      "—— Impurity: \tgini\n",
      "—— MaxBins: \t5\n",
      "—— MinInfoGain: 0.0\n",
      "—— MaxDepth: \t3\n"
     ]
    }
   ],
   "source": [
    "# getting best model parameters\n",
    "bestImpurity = bestModel.stages[-1]._java_obj.getImpurity()\n",
    "bestMaxBins = bestModel.stages[-1]._java_obj.getMaxBins()\n",
    "bestMinInfoGain = bestModel.stages[-1]._java_obj.getMinInfoGain()\n",
    "bestMaxDepth = bestModel.stages[-1]._java_obj.getMaxDepth()\n",
    "# print best parameters\n",
    "print(f'Best parameters:')\n",
    "print(f'—— Impurity: \\t{bestImpurity}')\n",
    "print(f'—— MaxBins: \\t{bestMaxBins}')\n",
    "print(f'—— MinInfoGain: {bestMinInfoGain}')\n",
    "print(f'—— MaxDepth: \\t{bestMaxDepth}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "70dbd334-2d4b-42de-9191-1515d15fc042",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make predictions with CV model - TEST data\n",
    "pred_cancellations_test = cvModel.transform(test_df)\n",
    "\n",
    "# predictions - TRAIN data\n",
    "pred_cancellations_train = cvModel.transform(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d12d7fc6-708f-492b-bdc7-f4a7104b7666",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'areaUnderROC'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "binaryEval.getMetricName()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c04bac95-33cb-49de-a8ff-f43924a3dd4f",
   "metadata": {},
   "source": [
    "## Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "471c3a07-39c8-4e65-8fa9-6a8cf29e9564",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training auROC: 1.0\n",
      "Test auROC: 1.0\n"
     ]
    }
   ],
   "source": [
    "binaryEval.setRawPredictionCol(\"rawPrediction\")\n",
    "trainAUROC = binaryEval.evaluate(pred_cancellations_train)\n",
    "testAUROC = binaryEval.evaluate(pred_cancellations_test)\n",
    "print(f'Training auROC: {trainAUROC}\\nTest auROC: {testAUROC}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "681e5281-5323-4360-9656-5a19baa975b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BinaryClassificationEvaluator_68c854277bc4"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "binaryEval.setMetricName('areaUnderPR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9db86bca-28a3-4910-86a3-df45a78ce5fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training auPR: 1.0\n",
      "Test auPR: 1.0\n"
     ]
    }
   ],
   "source": [
    "trainAUPR = binaryEval.evaluate(pred_cancellations_train)\n",
    "testAUPR = binaryEval.evaluate(pred_cancellations_test)\n",
    "print(f'Training auPR: {trainAUPR}\\nTest auPR: {testAUPR}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d05e691-98de-46ca-8fce-878c7b824505",
   "metadata": {},
   "source": [
    "References: https://github.com/enkeboll/data603-sp22/blob/main/homework/hw07-sparkml.ipynb\n",
    "\n",
    "#Was searching for references for pyspark ml online, but never found any that I could understand, ended up using the HW07 answer as a reference"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
